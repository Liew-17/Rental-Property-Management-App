# -*- coding: utf-8 -*-
"""web_scraper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CkCuEIwp3HQm9jjQjnPHSIkZiDLJoMu9
"""

!pip install selenium

!apt-get update
!apt-get install chromium chromium-driver

from selenium import webdriver

def web_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--verbose")
    options.add_argument('--no-sandbox')
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    options.add_argument("--window-size=1920, 1200")
    options.add_argument('--disable-dev-shm-usage')
    driver = webdriver.Chrome(options=options)
    return driver

from selenium.webdriver.common.by import By
import time
import pandas as pd
from datetime import datetime

driver = web_driver()
base_url = "https://www.fazwaz.my/property-for-rent/malaysia?page="

properties = {
    "title" : [],
    "address" : [],
    "price" : [],
    "size" : [],
    "bed" : [],
    "bath": [],
    "type": [],
    "update_date": []

}

page = 0

while True:
    page += 1
    url = base_url + str(page)
    driver.get(url)
    contents = driver.find_elements(By.CLASS_NAME, "result-search__item")
    progress = len(properties["title"])
    print(f"Scraping page {page}, current progress ({progress}/2000)")

    for content in contents:
        def scrape(attribute, class_name):
          try:
              a = content.find_element(By.CLASS_NAME, class_name).text.strip()
              properties[attribute].append(a)
          except:
              properties[attribute].append("")
              pass

        scrape("title","unit-name")
        scrape("address","location-unit")
        scrape("price","price-tag")

        last_update = None
        try:
          last_update = content.find_element(By.CSS_SELECTOR, "div.manage-tag__item:has(i.last-updated-message)").text
        except:
          pass

        properties["update_date"].append(last_update)

        bed, bath, size, ptype = None, None, None, None
        info_text = content.find_element(By.CLASS_NAME, "wrap-icon-info").text
        parts = [p.strip() for p in info_text.split("\n") if p.strip()]

        if len(parts) == 6:  # Studio case
          bed = "Studio"
          bath = parts[1]
          size = parts[3]
          ptype = parts[5]

        elif len(parts) == 7:  # Normal case
          bed = parts[0]
          bath = parts[2]
          size = parts[4]
          ptype = parts[6]

        properties["bed"].append(bed)
        properties["bath"].append(bath)
        properties["size"].append(size)
        properties["type"].append(ptype)

    if(len(properties["title"])>=2000): #collect 2000
      break

    time.sleep(3)


df = pd.DataFrame(properties)
today = datetime.today().strftime("%Y-%m-%d")
filename = f"properties_{today}.csv"

df.to_csv(filename, index=False, encoding="utf-8-sig")

