# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wEVVtyHnwVrPdgrttq-zM4ftz75st-We

Training Model and Generating Mean Encodings
"""

import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

df = pd.read_excel("processed_data.xlsx")
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

state_mean = train_df.groupby("state")["price"].mean()
train_df["state_mean"] = train_df["state"].map(state_mean)
test_df["state_mean"] = test_df["state"].map(state_mean)

town_mean = train_df.groupby("town")["price"].mean()
train_df["town_mean"] = train_df["town"].map(town_mean)
test_df["town_mean"] = test_df["town"].map(town_mean)

district_mean = train_df.groupby("district")["price"].mean()
train_df["district_mean"] = train_df["district"].map(district_mean)
test_df["district_mean"] = test_df["district"].map(district_mean)

type_mean = train_df.groupby("type")["price"].mean()
train_df["type_mean"] = train_df["type"].map(type_mean)
test_df["type_mean"] = test_df["type"].map(type_mean)

global_mean = train_df["price"].mean()

for col in ["state_mean", "town_mean", "district_mean", "type_mean"]:
    test_df[col] = test_df[col].fillna(global_mean) #fill missing
    train_df[col] = train_df[col].fillna(global_mean)

# Save mean values for future predictions
with open("mean_values.txt", "w", encoding="utf-8") as f:
    f.write("# GLOBAL MEAN\n")
    f.write(f"{global_mean:.2f}\n")

    f.write("# STATE MEANS\n")
    for k, v in state_mean.items():
        f.write(f"{k}: {v:.2f}\n")

    f.write("\n# TOWN MEANS\n")
    for k, v in town_mean.items():
        f.write(f"{k}: {v:.2f}\n")

    f.write("\n# DISTRICT MEANS\n")
    for k, v in district_mean.items():
        f.write(f"{k}: {v:.2f}\n")

    f.write("\n# TYPE MEANS\n")
    for k, v in type_mean.items():
        f.write(f"{k}: {v:.2f}\n")

print("Mean values saved to mean_values.txt")

features = ['size', 'bed', 'bath', 'type_mean', 'town_mean', 'district_mean', 'state_mean']
target = 'price'

X_train = train_df[features]
y_train = train_df[target]
X_test = test_df[features]
y_test = test_df[target]

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error: {mae:.2f}")
print(f"RÂ² Score: {r2:.2f}")

#save
joblib.dump(model, "price_model.pkl")

print("Model trained and saved as price_model.pkl")

"""Model Loading and Price Prediction"""

import joblib
import pandas as pd

model = joblib.load("price_model.pkl")

# new data (must match feature order)
new_data = pd.DataFrame([{
    'size': 655,
    'bed': 0,
    'bath': 1,
    'type': "penthouse",
    'town': "bandar johor bahru",
    'district': "johor bahru",
    'state': "johor"
}])

def read_mean_values(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        lines = f.readlines()

    data_sections = {
        "GLOBAL": 0,
        "STATE": {},
        "TOWN": {},
        "DISTRICT": {},
        "TYPE": {}
    }

    current_section = None
    for line in lines:
        line = line.strip()

        if not line:
            continue

        # Detect section headers
        if line.startswith("# GLOBAL"):
            current_section = "GLOBAL"
        elif line.startswith("# STATE"):
            current_section = "STATE"
        elif line.startswith("# TOWN"):
            current_section = "TOWN"
        elif line.startswith("# DISTRICT"):
            current_section = "DISTRICT"
        elif line.startswith("# TYPE"):
            current_section = "TYPE"
        else:
            # detect line wiht ":" and current section is not none.
            if current_section == "GLOBAL":
                data_sections["GLOBAL"] = float(line)
            elif ":" in line and current_section:
                k, v = line.split(":", 1)
                data_sections[current_section][k.strip()] = float(v.strip())

    return (
        data_sections["GLOBAL"],
        data_sections["STATE"],
        data_sections["TOWN"],
        data_sections["DISTRICT"],
        data_sections["TYPE"]
    )

global_mean, state_mean, town_mean, district_mean, type_mean = read_mean_values("mean_values.txt")

def predict(data):
    data["state_mean"] = data["state"].map(state_mean).fillna(global_mean)
    data["town_mean"] = data["town"].map(town_mean).fillna(global_mean)
    data["district_mean"] = data["district"].map(district_mean).fillna(global_mean)
    data["type_mean"] = data["type"].map(type_mean).fillna(global_mean)

    features = ['size', 'bed', 'bath', 'type_mean', 'town_mean', 'district_mean', 'state_mean']
    X = data[features]
    predicted_price = model.predict(X)
    print("Predicted price:", predicted_price[0])
    price_per_sqft = float(predicted_price[0]) / float(data['size'].iloc[0])
    print(f"P/S: {price_per_sqft:.2f}")

predict(new_data)